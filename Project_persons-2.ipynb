{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# https://codebeautify.org/htmlviewer/#\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persons_names = page.body.find_all(\"div\", title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in persons_names:\n",
    "    title = person[\"title\"]\n",
    "    data_persons[title] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.body.find_all(\"div\", class_=\"post person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persons = page.body.find_all(\"div\", class_=\"post person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_languages(link):\n",
    "    url = \"https://www.hse.ru\" + link\n",
    "    p = requests.get(url)\n",
    "    person_page = BeautifulSoup(p.text, 'html.parser')\n",
    "    \n",
    "    # Владение языками\n",
    "    try: \n",
    "        lang_list = person_page.body.find(\"dl\", class_=\"main-list large main-list-language-knowledge-level\").find_all(\"dd\")\n",
    "        lang_list = [lang.text for lang in lang_list]\n",
    "    except AttributeError:\n",
    "        lang_list = 'none'\n",
    "    \n",
    "    return lang_list\n",
    "    \n",
    "#get_languages('/org/persons/25477')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contacts(link):\n",
    "    url = \"https://www.hse.ru\" + link\n",
    "    p = requests.get(url)\n",
    "    person_page = BeautifulSoup(p.text, 'html.parser')\n",
    "    contacts = {\n",
    "        'phone_list': [],\n",
    "        #'mail_list': [],\n",
    "        'address': []\n",
    "    }\n",
    "    \n",
    "    contacts_box = person_page.body.find(\"dl\", class_=\"main-list large\")\n",
    "    #print(contacts_box.prettify())\n",
    "    try:\n",
    "        contents = contacts_box.find_all(\"dd\")\n",
    "        for box in contents: \n",
    "            if \"Телефон\" in box.text:\n",
    "                phone_list = box.text.split(\":\")[1:]\n",
    "                contacts['phone_list'] = phone_list\n",
    "\n",
    "            elif \"Электронная почта\" in box.text:\n",
    "                #mail_list = ['mail']\n",
    "                #contacts['mail_list'] = mail_list\n",
    "                continue\n",
    "\n",
    "            elif \"Адрес\" in box.text:\n",
    "                address = box.contents[0].split(\":\")[-1].strip()\n",
    "                contacts['address'] = address\n",
    "    except AttributeError:\n",
    "        pass        \n",
    "        \n",
    "    return contacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_science_info(link):\n",
    "    url = \"https://www.hse.ru\" + link\n",
    "    p = requests.get(url)\n",
    "    person_page = BeautifulSoup(p.text, 'html.parser')\n",
    "    ids = {}\n",
    "    \n",
    "    extra_info = person_page.find(\"dl\", class_=\"main-list person-extra-indent\")\n",
    "    try:\n",
    "        ids_info = extra_info.find_all('dd')\n",
    "    except AttributeError:\n",
    "        advisor_id = 'none'\n",
    "        return ids, advisor_id\n",
    "    \n",
    "    for dd in ids_info:\n",
    "        try: \n",
    "            id_name = dd.span.text\n",
    "            id_number = dd.a.text\n",
    "            ids[id_name] = id_number\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        advisor_tag = person_page.find(\"dl\", class_=\"main-list person-extra-indent\").next_sibling\n",
    "        advisor_id = advisor_tag.a['href']\n",
    "    except TypeError:\n",
    "        advisor_id = 'none'\n",
    "    \n",
    "    return ids, advisor_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'алгоритмы': '71848768',\n",
       " 'анализ данных': '61913648',\n",
       " 'анализ формальных понятий': '61296475'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_intersts(link):\n",
    "    url = \"https://www.hse.ru\" + link\n",
    "    p = requests.get(url)\n",
    "    person_page = BeautifulSoup(p.text, 'html.parser')\n",
    "    interests = {}\n",
    "    \n",
    "    try:\n",
    "        interests_div = person_page.find(\"div\", class_=\"b-person-data__inner b-person-data__tags\")\n",
    "        interests_tags = interests_div.find_all('a')\n",
    "        for a in interests_tags:\n",
    "            interest_name = a.text\n",
    "            interest_id = a['href'].split(\"=\")[1]\n",
    "            interests[interest_name] = interest_id\n",
    "    except AttributeError:\n",
    "        pass\n",
    "        \n",
    "    return interests\n",
    "    \n",
    "get_intersts('/staff/aparinov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"persons_Б.txt\", 'w', encoding=\"utf-8\") as outfile:\n",
    "    for person in persons:\n",
    "        name = person.find(\"div\", title=True)[\"title\"]\n",
    "        link = person.find(\"a\", href=True)[\"href\"]\n",
    "\n",
    "        lang_list = get_languages(link)\n",
    "        contacts_dict = get_contacts(link)\n",
    "        science_dict, advisor = get_science_info(link)\n",
    "        interests_dict = get_intersts(link)\n",
    "\n",
    "\n",
    "        data_persons[name] = {\n",
    "            \"link\": link,\n",
    "            \"languages\": lang_list,\n",
    "            \"contacts\": contacts_dict,\n",
    "            \"science_ids\": science_dict,\n",
    "            \"advisor\": advisor,\n",
    "            \"interests\": interests_dict\n",
    "\n",
    "\n",
    "        }\n",
    "        \n",
    "        \n",
    "    json.dump(data_persons, outfile, ensure_ascii=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"persons_A.txt\", 'w', encoding=\"utf-8\") as outfile:\n",
    "    json.dump(data_persons, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters_list = [\"В\", \"Г\", \"Д\", \"Е\", \"Ж\", \"З\", \"И\", \"К\", \"Л\", \"М\", \"Н\", \"О\", \"П\", \"Р\", \"С\", \"Т\",\n",
    "                \"У\", \"Ф\", \"Х\", \"Ц\", \"Ч\", \"Ш\", \"Щ\", \"Э\", \"Ю\", \"Я\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in letters_list:\n",
    "    link = \"https://www.hse.ru/org/persons/?ltr=\" + letter + \";udept=22726\"\n",
    "    data_persons = {}\n",
    "    \n",
    "    r = requests.get(link)\n",
    "    page = BeautifulSoup(r.text, 'html.parser')\n",
    "    persons_names = page.body.find_all(\"div\", title=True)\n",
    "    for person in persons_names:\n",
    "        title = person[\"title\"]\n",
    "        data_persons[title] = {}\n",
    "    \n",
    "    persons = page.body.find_all(\"div\", class_=\"post person\")\n",
    "    \n",
    "    for person in persons:\n",
    "        name = person.find(\"div\", title=True)[\"title\"]\n",
    "        link = person.find(\"a\", href=True)[\"href\"]\n",
    "\n",
    "        lang_list = get_languages(link)\n",
    "        contacts_dict = get_contacts(link)\n",
    "        science_dict, advisor = get_science_info(link)\n",
    "        interests_dict = get_intersts(link)\n",
    "\n",
    "\n",
    "        data_persons[name] = {\n",
    "            \"link\": link,\n",
    "            \"languages\": lang_list,\n",
    "            \"contacts\": contacts_dict,\n",
    "            \"science_ids\": science_dict,\n",
    "            \"advisor\": advisor,\n",
    "            \"interests\": interests_dict\n",
    "        }\n",
    "        \n",
    "    with open(\"persons_\"+letter+\".txt\", 'w', encoding=\"utf-8\") as outfile:\n",
    "        json.dump(data_persons, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
